summary(mtcarsfact)
cor(mtcars$disp,mtcars$hp)
cor(mtcars)
cor(mtcars$am)
cor(mtcars[9])
cor(mtcars[9,])
cor(mtcars)[9,]
save.image("D:/R/R-travail/MOOC R programming march2015/7-Regression models/Course Project regression models.RData")
data(mtcars)
summary(mtcars[,c(1,3:7)])
mtcarsfact <- as.data.frame(lapply(mtcars[,c(2,8,9,10,11)],as.factor))
summary(mtcarsfact)
par(mfrow=c(1,2))
boxplot(mtcars[-c(3,4)], xlab="Variable", ylab="Distribution", cex=0.7)
boxplot(mtcars[c(3,4)], xlab="Variable", ylab="Distribution", cex=0.7)
par(mfrow=c(1,2))
boxplot(mtcars[-c(3,4)], xlab="Variable", ylab="Distribution", cex=0.7)
means1 <- c(mean(mtcars$mpg),mean(mtcars$cyl),mean(mtcars$drat),mean(mtcars$wt),mean(mtcars$qsec),mean(mtcars$vs),mean(mtcars$am),mean(mtcars$gear),mean(mtcars$carb))
points(means1, col="red", pch=18)
boxplot(mtcars[c(3,4)], xlab="Variable", ylab="Distribution", cex=0.7)
means2 <- c(mean(mtcars$disp),mean(mtcars$hp),
points(means2,col="red",pch=18)
means2 <- c(mean(mtcars$disp),mean(mtcars$hp))
means2 <- c(mean(mtcars$disp),mean(mtcars$hp))
points(means2,col="red",pch=18)
fit <- lm(mpg~factor(am)+factor(cyl)+disp+hp+drat+wt+qsec+factor(vs)+factor(gear)+carb, data=mtcars)
summary(fit)
fit <- lm(mpg~factor(am), data=mtcars)
summary(fit)
summary(fit)$coef
round(summary(fit)$coef,3)
plot(fit)
par(mfrow=c(1,1))
plot(fit)
par(mfrow=c(2,2))
plot(fit)
fit2 <- lm(mpg~factor(am)+wt, data=mtcars)
round(summary(fit2)$coef,3)
fit3 <- lm(mpg~factor(am)+factor(cyl), data=mtcars)
round(summary(fit3)$coef,3)
anova(fit,fit3)
anova(fit,fit2)
fittout <- lm(mpg~., data=mtcars)
summary(fittout)
fittout <- lm(mpg~factor(am)+factor(cyl)+disp+hp+drat+wt+qsec+factor(vs)+factor(gear)+carb, data=mtcars)
summary(fittout)
round(cor(mtcars)[1,],2)
round(sort(cor(mtcars)[1,],2))
round(sort(cor(mtcars)[1,]),2)
round(cor(mtcars),2)
fit <- lm(mpg~factor(am), data=mtcars)
fit <- lm(, data=mtcars)
fit <- lm(mpg~factor(am), data=mtcars)
summary(fit)$r.squared
round(summary(fit)$coef,3)
fit2 <- lm(mpg~factor(am)+wt+factor(cyl)+hp, data=mtcars)
round(summary(fit2)$coef,3)
summary(fit2)$r.squared
summary(fit2)
fit2 <- lm(mpg~factor(am)+I(wt-mean(wt)+factor(cyl)+I(hp-mean(hp)), data=mtcars)
summary(fit2)
fit2 <- lm(mpg~factor(am)+I(wt-mean(wt))+factor(cyl)+I(hp-mean(hp)), data=mtcars)
summary(fit2)
relevel(mtcars$factor(cyl),"6")
relevel(mtcars$cyl,"6")
relevel(as.factor(mtcars$cyl),"6")
summary(fit2)
data(mtcars)
level6 <- relevel(as.factor(mtcars$cyl),"6")
summary(lm(mpg~factor(am)+I(wt-mean(wt))+level6+I(hp-mean(hp)), data=mtcars))
level6 <- relevel(as.factor(mtcars$cyl),"8")
summary(lm(mpg~factor(am)+I(wt-mean(wt))+level6+I(hp-mean(hp)), data=mtcars))
fit2 <- lm(mpg~factor(am)+I(wt-mean(wt))+factor(cyl)+I(hp-mean(hp)), data=mtcars)
round(summary(fit2)$coef,3)
summary(fit2)$r.squared
summary(fit2)
anova(fit,fit2)
fit2 <- lm(mpg~factor(am)+I(wt-mean(wt))+factor(cyl)+I(hp-mean(hp)), data=mtcars)
summary(fit2)
anova(fit,fit2)
fit3 <- lm(mpg~factor(am)+I(wt-mean(wt))+I(hp-mean(hp)), data=mtcars)
summary(fit3)
anova(fit3,fit2)
anova(fit3,fit)
summary(fit3)
sumCoef <- summary(fit3)$coefficients
summary(fit3)$coefficients
sumCoef[1,2]
sumCoef[2,1] + c(-1,1) * qt(0.975, df=fit$df)*sumCoef[1,2] # for the intercept
sumCoef[2,1]
sumCoef <- summary(fit3)$coefficients
sumCoef[2,1] + c(-1,1) * qt(0.975, df=fit3$df)*sumCoef[2,2]
plot(fit3)
anova(fit,fit2)$coef
anova(fit,fit2)$test
anova(fit,fit2)[1]
anova(fit,fit2)
anova(fit,fit2)|6]
anova(fit,fit2)[6]
summary(mtcarsfact)
barplot(mtcarsfact$cyl)
pie(table(mtcarsfact$cyl))
pie(table(mtcarsfact$cyl), labels="Cylinder number")
pie(table(mtcarsfact$cyl), main="Cylinder number")
par(mfrow(1,5))
pie(table(mtcarsfact$cyl), main="Cylinder number")
par(mfrow(1,5))
par(mfrow=c(1,5))
pie(table(mtcarsfact$cyl), main="Cylinder number")
pie(table(mtcarsfact$vs), main="Vs")
pie(table(mtcarsfact$am), main="Transmission")
pie(table(mtcarsfact$gear), main="# forward gears")
pie(table(mtcarsfact$carb), main="# carburetors")
anova(fit3,fit2)[6]
anova(fit3,fit2)$p
anova(fit3,fit2)$pr
anova(fit3,fit2)[6]
anova(fit3,fit)[6]
anova(fit3,fit2)[6][1]
anova(fit3,fit2)[6][2]
anova(fit,fit3,fit2)
anova(fitÃ©,fit3,fit)[6]
anova(fit2,fit3,fit)
anova(fit2,fit,fit3)
anova(fit3,fit,fit2)
anova(fit,fit2,fit3)[6]
anova(fit,fit2,fit3)
pie(table(mtcarsfact$cyl), main="Cylinder number")
pie(table(mtcarsfact$vs), main="Vs")
pie(table(mtcarsfact$am), main="Transmission")
pie(table(mtcarsfact$gear), main="# forward gears")
pie(table(mtcarsfact$carb), main="# carburetors")
par(mfrow=c(1,5))
par(mar=c(10,0,0,0))
pie(table(mtcarsfact$cyl), main="Cylinder number")
pie(table(mtcarsfact$vs), main="Vs")
pie(table(mtcarsfact$am), main="Transmission")
pie(table(mtcarsfact$gear), main="# forward gears")
pie(table(mtcarsfact$carb), main="# carburetors")
par(mar=c(5,0,0,0))
pie(table(mtcarsfact$cyl), main="Cylinder number")
pie(table(mtcarsfact$vs), main="Vs")
pie(table(mtcarsfact$am), main="Transmission")
pie(table(mtcarsfact$gear), main="# forward gears")
pie(table(mtcarsfact$carb), main="# carburetors")
par(mar=c(5,0,2,0))
pie(table(mtcarsfact$cyl), main="Cylinder number")
pie(table(mtcarsfact$vs), main="Vs")
pie(table(mtcarsfact$am), main="Transmission")
pie(table(mtcarsfact$gear), main="# forward gears")
pie(table(mtcarsfact$carb), main="# carburetors")
par(mfrow=c(1,5))
par(mar=c(5,0,2,0))
pie(table(mtcarsfact$cyl), main="Cyl")
pie(table(mtcarsfact$vs), main="Vs")
pie(table(mtcarsfact$am), main="am")
pie(table(mtcarsfact$gear), main="gears")
pie(table(mtcarsfact$carb), main="carb")
barplot(table(mtcarsfact$cyl), main="cyl")
barplot(table(mtcarsfact$vs), main="vs")
barplot(prop.table(table(mtcarsfact$vs), main="vs"))
barplot(prop.table(table(mtcarsfact$am), main="am"))
barplot(prop.table(table(mtcarsfact$carb), main="carb"))
par(mfrow=c(1,5))
par(mar=c(5,1,2,0))
barplot(prop.table(table(mtcarsfact$cyl), main="cyl"))
barplot(prop.table(table(mtcarsfact$vs), main="vs"))
barplot(prop.table(table(mtcarsfact$cyl)))
barplot(prop.table(table(mtcarsfact$vs)))
barplot(prop.table(table(mtcarsfact$carb)))
barplot(prop.table(table(mtcarsfact$gear)))
barplot(prop.table(table(mtcarsfact$am)))
plot(fit, which=2)
par(mfrow=c(1,1))
pie(table(mtcarsfact$cyl), main="cyl")
par(mfrow=c(1,2))
pie(table(mtcarsfact$cyl), main="cyl")
pie(table(mtcarsfact$vs), main="vs")
par(mfrow=c(1,5))
pie(table(mtcarsfact$cyl), main="cyl")
pie(table(mtcarsfact$vs), main="vs")
pie(table(mtcarsfact$am), main="am")
pie(table(mtcarsfact$gear), main="gear")
pie(table(mtcarsfact$carb), main="carb")
par(mfrow=c(1,5)mar=c(5,1,2,0), mgp = c(1.5, 0.3, 0))
pie(table(mtcarsfact$cyl), main="cyl")
pie(table(mtcarsfact$vs), main="vs")
pie(table(mtcarsfact$am), main="am")
pie(table(mtcarsfact$gear), main="gear")
pie(table(mtcarsfact$carb), main="carb")
par(mfrow=c(1,5)mar=c(5,1,2,0), mgp = c(3, 3, 0))
pie(table(mtcarsfact$cyl), main="cyl")
pie(table(mtcarsfact$vs), main="vs")
pie(table(mtcarsfact$am), main="am")
pie(table(mtcarsfact$gear), main="gear")
pie(table(mtcarsfact$carb), main="carb")
par(mfrow=c(1,5),mar=c(5,1,2,0), mgp = c(3, 3, 0))
pie(table(mtcarsfact$cyl), main="cyl")
pie(table(mtcarsfact$vs), main="vs")
pie(table(mtcarsfact$am), main="am")
pie(table(mtcarsfact$gear), main="gear")
pie(table(mtcarsfact$carb), main="carb")
par(mfrow=c(1,5),mar=c(5,1,2,0), mgp = c(0, 0, 0))
pie(table(mtcarsfact$cyl), main="cyl")
pie(table(mtcarsfact$vs), main="vs")
pie(table(mtcarsfact$am), main="am")
pie(table(mtcarsfact$gear), main="gear")
pie(table(mtcarsfact$carb), main="carb")
par(mfrow=c(1,5),mar=c(5,1,2,0))
pie(table(mtcarsfact$cyl), main="cyl")
pie(table(mtcarsfact$vs), main="vs")
pie(table(mtcarsfact$am), main="am")
pie(table(mtcarsfact$gear), main="gear")
pie(table(mtcarsfact$carb), main="carb")
save.image("D:/R/R-travail/MOOC R programming march2015/7-Regression models/Course Project regression models.RData")
install.packages("rrcovHD")
install.packages("rrcovHD")
install.packages("metabolomics")
library("ChemometricsWithR", lib.loc="D:/R/win-library")
library("ChemoSpec", lib.loc="D:/R/win-library")
install.packages("prospectr")
install.packages("prospectr")
install.packages("prospectr")
install.packages("prospectr")
library(ISLR)
library(ggplot2)
library(caret)
data(Wage)
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training); dim(testing)
featurePlot(x=training[,c("age","education","jobclass")], y=training$wage, plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,colour=jobclass,data=training)
qq <- qplot(age,wage,colour=education,data=training)
qq + geom_smooth(method="lm", formula=y~x)
library(Hmisc)
cutWage <- cut2(training$wage, g=3)
table(cutWage)
p1 <- qplot(cutWage, age, data=training, fill=cutWage, geom=c("boxplot"))
p1
p2 <- plot(cutWage, age, data=training, fill=cutWage, geom=c("boxplot","jitter"))
p2
p2 <- qplot(cutWage, age, data=training, fill=cutWage, geom=c("boxplot","jitter"))
p2
grid.arrange(p1,p2,ncol=2)
library(ggplot2)
install.packages("gridExtra")
grid.arrange(p1,p2,ncol=2)
(ISLR)
library(ISLR)
library(ggplot2)
library(caret)
grid.arrange(p1,p2,ncol=2)
library(gridExtra)
grid.arrange(p1,p2,ncol=2)
t1 <- table(cutWage, training$jobclass)
t1
prop.table(t1,1)
qplot(wage, colour=education, data=training, geom="density")
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE) # to create a training and test dataset
training <- spam[inTrain,]
testing <- spam[-inTrain,]
hist(training$capitalAve, main="", xlab="ave. capital run length")
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE) # to create a training and test dataset
training <- spam[inTrain,]
testing <- spam[-inTrain,]
hist(training$capitalAve, main="", xlab="ave. capital run length")
mean(training$capitalAve)
sd(training$capitalAve)
trainCapAve <- training$capitalAve
trainCapAveS <- (trainCapAve - mean(trainCapAve))/sd(trainCapAve)
mean(trainCapAveS)
sd(trainCapAveS)
testCapAve <- testing$capitalAve
testCapAveS <- (testCapAve - mean(trainCapAve))/sd(trainCapAve)
mean(testCapAveS)
sd(testCapAveS)
preObj <- preProcess(training[,-58], method=c("center","scale"))
trainCapAveS <- predict(preObj, training[,-58])$capitalAve
mean(trainCapAveS)
sd(trainCapAveS)
testCapAveS <- predict(preObj, testing[,-58])$capitalAve
mean(testCapAveS)
sd(testCapAveS)
set.seed(32343)
modelFit <- train(type ~., data=training, preProcess=c("center","scale"), method="glm")
modelFit
preObj <- preProcess(training[,-58], method=c("BoxCox"))
trainCapAveS <- predict(preObj, training[,-58])$capitalAve
par(mfrow=c(1,2))
hist(trainCapAveS)
qqnorm(trainCapAveS)
# make some values NA
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1], size=1, prob=0.05)==1
training$capAve[selectNA] <- NA
# impute and standardize
preObj <- preProcess(training[,-58], method="knnImpute")
capAve <- predict(preObj, training[,-58])$capAve
# standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruh-mean(capAveTruth))/sd(capAveTruth)
install.packages("RANN")
# make some values NA
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1], size=1, prob=0.05)==1
training$capAve[selectNA] <- NA
# impute and standardize
preObj <- preProcess(training[,-58], method="knnImpute")
capAve <- predict(preObj, training[,-58])$capAve
# standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruh-mean(capAveTruth))/sd(capAveTruth)
set.seed(13343)
# make some values NA
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1], size=1, prob=0.05)==1
training$capAve[selectNA] <- NA
# impute and standardize
preObj <- preProcess(training[,-58], method="knnImpute")
capAve <- predict(preObj, training[,-58])$capAve
# standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
quantile(capAve - capAveTruth)
quantile((capAve-capAveTruth)[selectNA])
quantile((capAve-capAveTruth)[!selectNA])
library(ISLR)
library(caret)
data(Wage)
inTrain <- createDataPartition(y=Wage$Wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
Wage$Wage
Wage$wage
library(ISLR)
library(caret)
data(Wage)
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
table(training$jobclass)
dummies <- dummyVars(wage ~ jobclass, data=training)
dummies <- dummyVars(wage ~ jobclass, data=training)
head(predict(dummies, newdata=training))
nsv <- nearZeroVar(training, saveMetrics=TRUE)
nsv
library(splines)
bsBasis <- bs(training$age, df=3) # 3rd degree polynomial
bsBasis
head(bsBasis)
library(splines)
bsBasis <- bs(training$age, df=3) # 3rd degree polynomial
head(bsBasis)
plot(training$age, training$wage, pch=19, cex=0.5)
lm1 <- lm(wage~bsBasis, data=training)
plot(training$age, training$wage, pch=19, cex=0.5)
points(training$age, predict(lm1, newdata=training), col="red", pch=19, cex=0.5)
par(mfrow=c(1,1))
plot(training$age, training$wage, pch=19, cex=0.5)
points(training$age, predict(lm1, newdata=training), col="red", pch=19, cex=0.5)
predict(bsBasis, age=testing$age)
head(predict(bsBasis, age=testing$age))
data(spam)
inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE) # to create a training and test dataset
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[,-58])) # 58= spam/ham
diag(M) <- 0 # diag=cor(x1 by x1)=1 so not interesting. So put = 0
wich(M > 0.8, arr.ind=T)
which(M > 0.8, arr.ind=T)
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE) # to create a training and test dataset
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[,-58])) # 58= spam/ham
diag(M) <- 0 # diag=cor(x1 by x1)=1 so not interesting. So put = 0
which(M > 0.8, arr.ind=T)
names(spam)[c(34,32)]
plot(spam[,34], spam[,32])
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(Ozone)
data(ozone)
ozone <- ozone[order(ozone$ozone),]
head(ozone)
ll <- matrix(NA, nrow=10, ncol=155)
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=TRUE)
ozone0 <- ozone[ss,]
ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone, data=ozone0, span=0.2)
ll[i,] <- predict(loess0, newdata=data.frame(ozone=1:155))
}
View(ozone0)
summary(ll)
dim(ozone)[1]
sample(1:1,replace=TRUE)
ss <- sample(1,replace=TRUE)
sample(1,replace=TRUE)
sample(1:2,replace=TRUE)
sample(1:5,replace=TRUE)
ss <- sample(1:dim(ozone)[1],replace=TRUE)
ozone0 <- ozone[ss,]
ozone0
nrows(ozone0)
nrow(ozone0)
ozone0[order(ozone0$ozone),]
ozone0
ozone0 <- ozone0[order(ozone0$ozone),]
ozone0
loess0 <- loess(temperature ~ ozone, data=ozone0, span=0.2)
loess0
ll <- matrix(NA, nrow=10, ncol=155)
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=TRUE)
ozone0 <- ozone[ss,]
ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone, data=ozone0, span=0.2)
ll[i,] <- predict(loess0, newdata=data.frame(ozone=1:155))
}
ll <- matrix(NA, nrow=10, ncol=155)
data(ozone)
ozone <- ozone[order(ozone$ozone),]
head(ozone)
ll <- matrix(NA, nrow=10, ncol=155)
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=TRUE)
ozone0 <- ozone[ss,]
ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone, data=ozone0, span=0.2)
ll[i,] <- predict(loess0, newdata=data.frame(ozone=1:155))
}
plot(ozone$ozone, ozone$temperature, pch=19, cex=0.5)
for(i in 1:10){
lines(1:155, ll[i,],col="grey", lwd=2)
}
lines(1:155, apply(ll,2,mean),col="red",lwd=2)
setwd("D:/R/R-travail/MOOC R programming march2015/8-Machine Learning")
traintest <- read.csv("pml-training.csv", na.strings="#DIV/O!")
validation <- read.csv("pml-testing.csv", sep=",")
library(caret)
library(ggplot2)
colnum <- c(12:36,50:59,69:83,87:101,103:112,125:139,141:150)
for(i in colnum){traintest[,i]<-as.numeric(as.character(traintest[,i]))}
for(i in colnum){validation[,i]<-as.numeric(as.character(validation[,i]))}
set.seed(36987)
InTrain <- createDataPartition(y=traintest$classe, p=0.7, list=FALSE)
training <- traintest[InTrain,]
testing <- traintest[-InTrain,]
nsv <- nearZeroVar(training, saveMetrics=TRUE)
featurenul <- row.names(subset(nsv, nsv$zeroVar==TRUE))
summary(training[,featurenul])
nbfeaturenul <- which(colnames(training) %in% featurenul)
print(featurenul)
na_count <-sapply(training[,-nbfeaturenul], function(y) sum(length(which(is.na(y)))))
na_count <- as.data.frame(na_count)
# a lot of variables have more than 13400 NA, which is more than 97% of the values. They don't have to enter in our model.
featureNA <- row.names(subset(na_count, na_count!=0))
nbfeatureNA <- which(colnames(training) %in% featureNA)
featuregood <- c(1:160)
featuregood <- featuregood[-c(1:7,nbfeatureNA,nbfeaturenul)]
dim(training[,featuregood])
featurePlot(training[,featuregood[1:5]], y=training$classe, plot="pairs")
featurePlot(training[,featuregood[1]], y=training$classe, plot="box")
featurePlot(training[,featuregood[1]], y=training$classe, plot="strip")
featurePlot(training[,featuregood[1]], y=training$classe, plot="pairs")
featurePlot(training[,featuregood[1]], y=training$classe, plot="ellipse")
featurePlot(training[,featuregood[1]], y=training$classe, plot="density")
featurePlot(training[,featuregood[1:2]], y=training$classe, plot="density")
install.packages("moments")
library(moments)
skewness(training[,featuregood[1:2]])
skewness(training[,featuregood[1:52]])
kurtosis(training[,featuregood[1:52]])
M <- abs(cor(training[,featuregood[1:52]]))
diag(M) <- 0 # diag=cor(x1 by x1)=1 so not interesting. So put = 0
which(M > 0.8, arr.ind=T)
dim(which(M > 0.8, arr.ind=T))
M
M <- abs(cor(training[,featuregood[1:52]]))
M
diag(M) <- 0 # diag=cor(x1 by x1)=1 so not interesting. So put = 0
M
which(M > 0.8, arr.ind=T)
dim(which(M > 0.8, arr.ind=T))
model <- train(training$classe~training[,featuregood[1:52]],method="rf",preProcess=c("center","scale","pca"), trControl=trainCOntrol(number=5, allowParallel=TRUE))
names(training[,featuregood[1:52]])
model <- train(classe~feature, data=training, method="rf",preProcess=c("center","scale","pca"), trControl=trainCOntrol(number=5, allowParallel=TRUE))
feature <- names(training[,featuregood[1:52]])
model <- train(classe~feature, data=training, method="rf",preProcess=c("center","scale","pca"), trControl=trainCOntrol(number=5, allowParallel=TRUE))
model <- train(classe~feature, data=training)
sumfeature <- for i 1:length(feature){feature[i]+feature{i+1}}
sumfeature <- for i 1:length(feature){sumfeature[i]+sumfeature{i+1}}
sumfeature <- for i 1:length(feature){feature[i]+feature[i+1]}
sumfeature <- for(i 1:length(feature)){feature[i]+feature[i+1]}
sumfeature <- for(i in 1:length(feature)){feature[i]+feature[i+1]}
fmla <- as.formula(paste("classe ~ ", paste(feature, collapse= "+")))
fmla
model <- train(fmla, data=training, method="rf",preProcess=c("center","scale","pca"), trControl=trainCOntrol(number=5, allowParallel=TRUE))
model <- train(fmla, data=training, method="rf",preProcess=c("center","scale","pca"), trControl=trainControl(number=5, allowParallel=TRUE))
